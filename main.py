import telebot
import requests
from bs4 import BeautifulSoup
import feedparser
import hashlib
import time
import re
import threading
from deep_translator import GoogleTranslator
from dateutil import parser

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ---
BOT_TOKEN = "8053411183:AAGPglnG3gQ5-V052RA1e9qqGQR9x8tPMB0"
CHAT_ID = 843629315

bot = telebot.TeleBot(BOT_TOKEN)
last_sent_ids = set()

RSS_FEEDS = [
    "https://www.fxstreet.com/rss/news",
    "https://www.forexlive.com/feed",
    "https://www.investing.com/rss/news_25.rss",
    "https://www.instaforex.com/rss/calendar",
]

def clean_text(text):
    text = BeautifulSoup(text, "html.parser").get_text()
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'www\.\S+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def translate_text(text, target_lang="uk"):
    try:
        return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception as e:
        print(f"Translation error: {e}")
        return text

def analyze_sentiment(text):
    text_lower = text.lower()
    positive_words = ['–∑–º—ñ—Ü–Ω', '–∑—Ä–æ—Å—Ç–∞', '–ø—ñ–¥–≤–∏—â', '–ø–æ–∫—Ä–∞—â', '–ø—ñ–¥–π–æ–º', '–ø–æ–∑–∏—Ç–∏–≤', '–ø—ñ–¥—Ç—Ä–∏–º–∫', '–æ–ø—Ç–∏–º—ñ—Å—Ç']
    negative_words = ['–ø–∞–¥—ñ–Ω', '—Å–ø–∞–¥', '—Å–ª–∞–±—à', '–ø–æ–≥—ñ—Ä—à', '–∑–Ω–∏–∂–µ–Ω', '–Ω–µ–≥–∞—Ç–∏–≤', '—Ä–∏–∑–∏–∫', '–ø–µ—Å–∏–º—ñ—Å—Ç']

    pos_score = sum(word in text_lower for word in positive_words)
    neg_score = sum(word in text_lower for word in negative_words)

    if pos_score > neg_score:
        return "üìà –ü—Ä–æ–≥–Ω–æ–∑: –Ñ–≤—Ä–æ –∑–º—ñ—Ü–Ω—é—î—Ç—å—Å—è"
    elif neg_score > pos_score:
        return "üìâ –ü—Ä–æ–≥–Ω–æ–∑: –Ñ–≤—Ä–æ —Å–ª–∞–±—à–∞—î"
    else:
        return "üîç –ü—Ä–æ–≥–Ω–æ–∑: –†–∏–Ω–æ–∫ —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π"

def format_news_message(title, summary, source=None, impact=None, prediction=None, time_str=None):
    title_uk = translate_text(title)
    summary_uk = translate_text(summary)
    summary_uk = clean_text(summary_uk)
    sentences = re.split(r'(?<=[.!?]) +', summary_uk)
    short_summary = ' '.join(sentences[:2])
    if len(short_summary) > 350:
        short_summary = short_summary[:347] + "..."

    msg = ""
    if source:
        msg += f"üì∞ –î–∂–µ—Ä–µ–ª–æ: {source}\n"
    if time_str:
        msg += f"üïí –ß–∞—Å: {time_str}\n"
    msg += f"\nüóûÔ∏è *{title_uk}*\n\n"
    msg += f"{short_summary}\n\n"
    if impact:
        impact_uk = translate_text(impact)
        msg += f"‚ö° –í–ø–ª–∏–≤: {impact_uk}\n"
    if prediction:
        msg += f"{prediction}\n"
    return msg

def parse_news():
    url = "https://www.investing.com/economic-calendar/"
    headers = {"User-Agent": "Mozilla/5.0"}
    output = []
    try:
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
    except Exception as e:
        print(f"Error fetching calendar: {e}")
        return output

    table = soup.find("table", {"id": "economicCalendarData"})
    if not table:
        return output

    rows = table.find_all("tr", {"class": "js-event-item"})
    for row in rows:
        event_id = row.get("data-event-id")
        if not event_id or event_id in last_sent_ids:
            continue

        time_tag = row.get("data-event-datetime")
        try:
            time_obj = parser.parse(time_tag) if time_tag else None
            time_str = time_obj.strftime("%Y-%m-%d %H:%M") if time_obj else "‚Äî"
        except:
            time_obj = None
            time_str = "‚Äî"

        currency = row.get("data-event-currency")
        impact = row.get("data-impact")
        title = row.find("td", {"class": "event"}).get_text(strip=True)
        actual = row.get("data-actual") or "‚Äî"
        forecast = row.get("data-forecast") or "‚Äî"

        # –§—ñ–ª—å—Ç—Ä –ø–æ –≤–∞–ª—é—Ç—ñ —Ç–∞ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ
        if currency in ("EUR", "USD") and impact in ("3", "2"):
            prediction = f"üìà –ü—Ä–æ–≥–Ω–æ–∑: –§–∞–∫—Ç {actual} –ø—Ä–æ—Ç–∏ –ü—Ä–æ–≥–Ω–æ–∑—É {forecast}"
            source = "Investing.com"
            msg = format_news_message(
                title=title,
                summary=f"–§–∞–∫—Ç: {actual} | –ü—Ä–æ–≥–Ω–æ–∑: {forecast}",
                source=source,
                impact="–í–∏—Å–æ–∫–∏–π" if impact == "3" else "–°–µ—Ä–µ–¥–Ω—ñ–π",
                prediction=prediction,
                time_str=time_str
            )
            output.append((event_id, msg, time_obj))
    return output

def parse_rss_news():
    output = []
    for feed_url in RSS_FEEDS:
        try:
            feed = feedparser.parse(feed_url)
        except Exception as e:
            print(f"Error parsing feed {feed_url}: {e}")
            continue

        for entry in feed.entries:
            title = entry.get('title', '')
            summary = entry.get('summary', '') or entry.get('description', '')

            title_clean = clean_text(title)
            if not any(sym in title_clean.upper() for sym in ["EUR", "USD", "EUR/USD"]):
                continue

            id_hash = hashlib.md5(title_clean.encode("utf-8")).hexdigest()
            if id_hash in last_sent_ids:
                continue

            published = getattr(entry, 'published', None)
            try:
                time_obj = parser.parse(published) if published else None
            except:
                time_obj = None

            source = re.findall(r'https?://(?:www\.)?([^/]+)/', feed_url)
            source_name = source[0] if source else "–ù–æ–≤–∏–Ω–∏"

            prediction = analyze_sentiment(summary)

            msg = format_news_message(title, summary, source=source_name, time_str=(time_obj.strftime("%Y-%m-%d %H:%M") if time_obj else None), prediction=prediction)
            output.append((id_hash, msg, time_obj))
    return output

def job():
    global last_sent_ids
    news_from_calendar = parse_news()
    news_from_rss = parse_rss_news()

    all_news = news_from_calendar + news_from_rss
    new_news = [(nid, msg, t) for (nid, msg, t) in all_news if nid not in last_sent_ids]
    new_news = [item for item in new_news if item[2] is not None]

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —á–∞—Å–æ–º –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó (–Ω–∞–π—Å—Ç–∞—Ä—ñ—à—ñ - –ø–µ—Ä—à–∏–º–∏)
    new_news.sort(key=lambda x: x[2], reverse=False)

    for nid, msg, _ in new_news:
        try:
            bot.send_message(CHAT_ID, msg, parse_mode="Markdown")
            last_sent_ids.add(nid)
        except Exception as e:
            print(f"Error sending message: {e}")

@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.reply_to(message, "üëã –í—ñ—Ç–∞—é! –Ø –Ω–∞–¥—Å–∏–ª–∞—Ç–∏–º—É —Å–≤—ñ–∂—ñ –Ω–æ–≤–∏–Ω–∏ –ø–æ –ø–∞—Ä—ñ EUR/USD –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –∞–Ω–∞–ª—ñ–∑–æ–º —ñ –ø—Ä–æ–≥–Ω–æ–∑–æ–º –∫–æ–∂–Ω—ñ 5 —Ö–≤–∏–ª–∏–Ω.")

def main():
    def news_loop():
        while True:
            try:
                job()
            except Exception as e:
                print(f"Error in job: {e}")
            time.sleep(300)  # 5 —Ö–≤–∏–ª–∏–Ω

    threading.Thread(target=news_loop, daemon=True).start()
    bot.polling()

if __name__ == "__main__":
    main()
