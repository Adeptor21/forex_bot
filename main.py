import telebot
import requests
from bs4 import BeautifulSoup
import feedparser
import hashlib
import time
import re
import threading
from deep_translator import GoogleTranslator

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ---
BOT_TOKEN = "8053411183:AAGPglnG3gQ5-V052RA1e9qqGQR9x8tPMB0"
CHAT_ID = 843629315

bot = telebot.TeleBot(BOT_TOKEN)
last_sent_ids = set()

RSS_FEEDS = [
    "https://www.fxstreet.com/rss/news",
    "https://www.forexlive.com/feed",
    "https://www.investing.com/rss/news_25.rss",
    "https://www.instaforex.com/rss/calendar",
]

# --- –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó ---

def clean_text(text):
    text = BeautifulSoup(text, "html.parser").get_text()
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'www\.\S+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def translate_text(text, target_lang="uk"):
    try:
        return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception as e:
        print(f"Translation error: {e}")
        return text

def make_prediction(actual, forecast, currency):
    try:
        a = float(actual.replace('%','').replace(',', '.'))
        f = float(forecast.replace('%','').replace(',', '.'))
        if currency == "EUR":
            if a > f: return "üìà –ü—Ä–æ–≥–Ω–æ–∑: –Ñ–≤—Ä–æ –∑–º—ñ—Ü–Ω—é—î—Ç—å—Å—è"
            elif a < f: return "üìâ –ü—Ä–æ–≥–Ω–æ–∑: –Ñ–≤—Ä–æ —Å–ª–∞–±—à–∞—î"
        if currency == "USD":
            if a > f: return "üìà –ü—Ä–æ–≥–Ω–æ–∑: –î–æ–ª–∞—Ä –∑–º—ñ—Ü–Ω—é—î—Ç—å—Å—è"
            elif a < f: return "üìâ –ü—Ä–æ–≥–Ω–æ–∑: –î–æ–ª–∞—Ä —Å–ª–∞–±—à–∞—î"
        return "üîç –ü—Ä–æ–≥–Ω–æ–∑: –†–∏–Ω–æ–∫ —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π"
    except:
        return "‚ÑπÔ∏è –ü—Ä–æ–≥–Ω–æ–∑: –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö"

def format_news_message(title, summary, source=None, impact=None, prediction=None):
    # –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —ñ –æ–ø–∏—Å—É
    title_uk = translate_text(title)
    summary_uk = translate_text(summary)

    # –ß–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É —ñ —Å–∫–æ—Ä–æ—á–µ–Ω–Ω—è –¥–æ 2 —Ä–µ—á–µ–Ω—å
    summary_uk = clean_text(summary_uk)
    sentences = re.split(r'(?<=[.!?]) +', summary_uk)
    short_summary = ' '.join(sentences[:2])
    if len(short_summary) > 350:
        short_summary = short_summary[:347] + "..."

    # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ —ñ–∫–æ–Ω–∫–∞–º–∏
    msg = ""
    if source:
        msg += f"üì∞ –î–∂–µ—Ä–µ–ª–æ: {source}\n"
    msg += f"üóûÔ∏è *{title_uk}*\n\n"
    msg += f"{short_summary}\n\n"
    if impact:
        impact_uk = translate_text(impact)
        msg += f"‚ö° –í–ø–ª–∏–≤: {impact_uk}\n"
    if prediction:
        msg += f"{prediction}\n"
    return msg

# --- –§—É–Ω–∫—Ü—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É –µ–∫–æ–Ω–æ–º—ñ—á–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è Investing.com ---

def parse_news():
    url = "https://www.investing.com/economic-calendar/"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
    except Exception as e:
        print(f"Error fetching calendar: {e}")
        return []

    output = []
    table = soup.find("table", {"id": "economicCalendarData"})
    if not table:
        return []

    rows = table.find_all("tr", {"class": "js-event-item"})
    for row in rows:
        event_id = row.get("data-event-id")
        if not event_id or event_id in last_sent_ids:
            continue

        time_tag = row.get("data-event-datetime")  # —Ñ–æ—Ä–º–∞—Ç: "2025-06-30 07:30:00"
        time_str = time_tag[-8:-3] if time_tag else "‚Äî"

        currency = row.get("data-event-currency")
        impact = row.get("data-impact")
        title = row.find("td", {"class": "event"}).get_text(strip=True)
        actual = row.get("data-actual") or "‚Äî"
        forecast = row.get("data-forecast") or "‚Äî"

        # –§—ñ–ª—å—Ç—Ä –ø–æ –≤–∞–ª—é—Ç—ñ —ñ –≤–ø–ª–∏–≤—É (3 - –≤–∏—Å–æ–∫–∏–π, 2 - —Å–µ—Ä–µ–¥–Ω—ñ–π)
        if currency in ("EUR", "USD") and impact in ("3", "2"):
            prediction = make_prediction(actual, forecast, currency)
            source = "Investing.com"
            msg = f"üïí {time_str}\n"
            msg += format_news_message(
                title=title,
                summary=f"–§–∞–∫—Ç: {actual} | –ü—Ä–æ–≥–Ω–æ–∑: {forecast}",
                source=source,
                impact=f"–í–∏—Å–æ–∫–∏–π" if impact == "3" else "–°–µ—Ä–µ–¥–Ω—ñ–π",
                prediction=prediction
            )
            output.append((event_id, msg))
    return output

# --- –§—É–Ω–∫—Ü—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É RSS-—Å—Ç—Ä—ñ—á–æ–∫ ---

def parse_rss_news():
    output = []
    for feed_url in RSS_FEEDS:
        try:
            feed = feedparser.parse(feed_url)
        except Exception as e:
            print(f"Error parsing feed {feed_url}: {e}")
            continue

        for entry in feed.entries:
            title = entry.get('title', '')
            summary = entry.get('summary', '') or entry.get('description', '')

            title_clean = clean_text(title)
            # –§—ñ–ª—å—Ç—Ä –ø–æ EUR/USD —É –∑–∞–≥–æ–ª–æ–≤–∫—É
            if not any(sym in title_clean.upper() for sym in ["EUR", "USD", "EUR/USD"]):
                continue

            id_hash = hashlib.md5(title_clean.encode("utf-8")).hexdigest()
            if id_hash in last_sent_ids:
                continue

            # –î–∂–µ—Ä–µ–ª–æ –±–µ—Ä–µ–º–æ —ñ–∑ feed_url –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏
            source = re.findall(r'https?://(?:www\.)?([^/]+)/', feed_url)
            source_name = source[0] if source else "–ù–æ–≤–∏–Ω–∏"

            msg = format_news_message(title, summary, source=source_name)
            output.append((id_hash, msg))
    return output

# --- –û—Å–Ω–æ–≤–Ω–∞ —Ä–æ–±–æ—Ç–∞: –∑–±—ñ—Ä –Ω–æ–≤–∏–Ω —ñ –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è ---

def job():
    global last_sent_ids
    news_from_calendar = parse_news()
    news_from_rss = parse_rss_news()

    all_news = news_from_calendar + news_from_rss
    new_news = [(nid, msg) for nid, msg in all_news if nid not in last_sent_ids]

    for nid, msg in new_news:
        try:
            bot.send_message(CHAT_ID, msg, parse_mode="Markdown")
            last_sent_ids.add(nid)
        except Exception as e:
            print(f"Error sending message: {e}")

# --- –û–±—Ä–æ–±–Ω–∏–∫ –∫–æ–º–∞–Ω–¥–∏ /start ---

@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.reply_to(message, "üëã –í—ñ—Ç–∞—é! –Ø –Ω–∞–¥—Å–∏–ª–∞—Ç–∏–º—É —Å–≤—ñ–∂—ñ –Ω–æ–≤–∏–Ω–∏ –ø–æ –ø–∞—Ä—ñ EUR/USD –∫–æ–∂–Ω—ñ 5 —Ö–≤–∏–ª–∏–Ω.")

# --- –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É ---

def main():
    def news_loop():
        while True:
            try:
                job()
            except Exception as e:
                print(f"Error in job: {e}")
            time.sleep(300)  # 5 —Ö–≤–∏–ª–∏–Ω

    threading.Thread(target=news_loop, daemon=True).start()
    bot.polling()

if __name__ == "__main__":
    main()
